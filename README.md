# Findly

[![Docker Deployment](https://github.com/OmarZakaria10/PricePointScout/actions/workflows/nodetest.yml/badge.svg)](https://github.com/OmarZakaria10/PricePointScout/actions/workflows/nodetest.yml)
[![Node.js](https://img.shields.io/badge/Node.js-18+-green?logo=node.js)](https://nodejs.org/)
[![MongoDB](https://img.shields.io/badge/MongoDB-6.0+-green?logo=mongodb)](https://mongodb.com/)
[![Redis](https://img.shields.io/badge/Redis-6.0+-red?logo=redis)](https://redis.io/)
[![Express.js](https://img.shields.io/badge/Express.js-4.x-blue?logo=express)](https://expressjs.com/)
[![Kubernetes](https://img.shields.io/badge/Kubernetes-Ready-blue?logo=kubernetes)](https://kubernetes.io/)
[![Terraform](https://img.shields.io/badge/Terraform-Infrastructure-purple?logo=terraform)](https://terraform.io/)
[![Jenkins](https://img.shields.io/badge/Jenkins-CI%2FCD-orange?logo=jenkins)](https://jenkins.io/)
[![Ansible](https://img.shields.io/badge/Ansible-Automation-red?logo=ansible)](https://ansible.com/)
[![Docker](https://img.shields.io/badge/Docker-Containerized-blue?logo=docker)](https://docker.com/)
[![Azure](https://img.shields.io/badge/Azure-Cloud-blue?logo=microsoftazure)](https://azure.microsoft.com/)
[![Prometheus](https://img.shields.io/badge/Prometheus-Monitoring-orange?logo=prometheus)](https://prometheus.io/)
[![Grafana](https://img.shields.io/badge/Grafana-Visualization-orange?logo=grafana)](https://grafana.com/)

**Enterprise-grade e-commerce price comparison platform with complete cloud-native DevOps implementation**

Findly is a production-ready, scalable price comparison service that demonstrates modern software engineering practices from development to deployment. This project showcases a complete DevOps pipeline with multi-cloud infrastructure, container orchestration, and automated CI/CD workflows.

## ğŸ—ï¸ Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Load Balancer â”‚    â”‚   Kubernetes     â”‚    â”‚   Monitoring    â”‚
â”‚   (NGINX)       â”‚â”€â”€â”€â”€â”‚   Cluster        â”‚â”€â”€â”€â”€â”‚   (Prometheus)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚         â”‚         â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â” â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â” â”Œâ”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
              â”‚ Node.js â”‚ â”‚ MongoDB â”‚ â”‚  Redis  â”‚
              â”‚   App   â”‚ â”‚ Replica â”‚ â”‚ Cache   â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ï¿½ Development Features

### Core Application
- **ğŸ¯ Multi-Source Price Scraping**: Advanced web scraping engine supporting Amazon, Jumia, Noon, and ElBadr
- **âš¡ High-Performance Caching**: Redis-powered intelligent caching with TTL management
- **ğŸ” Enterprise Security**: JWT authentication, bcrypt hashing, rate limiting, XSS protection
- **ğŸ“Š RESTful API**: Clean, documented API with comprehensive error handling
- **ğŸ¨ Modular Architecture**: MVC pattern with separation of concerns

### Scraping Engine
- **ğŸ”§ Base Scraper Class**: Extensible OOP design for easy platform integration
- **ğŸ“„ Multiple Pagination Support**: URL-based, button-click, and infinite scroll
- **ğŸ›¡ï¸ Anti-Detection**: Puppeteer with stealth plugin and user-agent rotation
- **âš¡ Concurrent Processing**: Parallel scraping with configurable worker pools
- **ğŸ”„ Error Recovery**: Retry mechanisms and graceful failure handling

### Data Management
- **ğŸ“Š MongoDB Integration**: Mongoose ODM with schema validation
- **ğŸ” Advanced Search**: Full-text search with filtering and sorting
- **ğŸ“ˆ User Analytics**: Search history and preference tracking
- **ğŸ’¾ Data Persistence**: Automated backups and data integrity checks



**Usage & Benefits:**
```bash
# Development with hot reload
docker-compose up -d

# Production deployment
docker build -t pricepointscout .
docker run -p 8080:8080 pricepointscout
```


**Usage Workflow:**
```bash
# Initialize and plan
terraform init
terraform plan -var="node_count=3" -var="resource_group_location=uaenorth"

# Apply with approval
terraform apply

# Get cluster credentials
az aks get-credentials --resource-group $(terraform output -raw resource_group_name) --name $(terraform output -raw kubernetes_cluster_name)
```


### ğŸ—ï¸ Backend Development Approach

- **Asynchronous Processing**: Perfect for I/O-intensive web scraping operations
- **Rich Ecosystem**: Extensive npm packages for security, validation, and utilities
- **JavaScript Everywhere**: Consistent language across frontend and backend
- **Rapid Development**: Fast prototyping and iteration capabilities

**MVC Pattern Implementation:**
- **Controllers**: Handle HTTP requests, validation, and response formatting
- **Models**: Database schemas with business logic and validation rules
- **Routes**: Clean URL structure with middleware integration
- **Middleware**: Layered security, logging, and request processing

- **Input Validation**: Mongoose schemas prevent invalid data storage
- **Injection Prevention**: mongo-sanitize and XSS-clean middleware protect against attacks
- **Rate Limiting**: Prevents abuse and DDoS attacks
- **Authentication**: JWT tokens with secure HTTP-only cookies

### ğŸ” Authentication & Security Implementation

 implemented enterprise-grade authentication focusing on security and usability:

**Token Management:**
- **Secure Storage**: HTTP-only cookies prevent XSS token theft
- **Expiration Handling**: 90-day token lifetime with automatic refresh
- **Cross-Site Protection**: SameSite cookie attribute prevents CSRF attacks
- **Environment-Aware**: HTTPS-only cookies in production environments

**Password Security:**
- **Bcrypt Hashing**: 12 salt rounds provide strong protection against rainbow table attacks
- **Password Reset**: Crypto-based tokens with 10-minute expiration for security
- **Validation Rules**: Minimum 8 characters with complexity requirements

### ğŸ•·ï¸ Web Scraping Engine Architecture

Off-the-shelf solutions couldn't handle the complexity and anti-detection requirements needed for production e-commerce scraping.

**Object-Oriented Design Philosophy:**

**BaseScraper Class - Framework Foundation:**
- **Extensibility**: New e-commerce sites require only configuration, not code rewriting
- **Pagination Support**: Handles URL-based, button-click, and infinite scroll patterns
- **Anti-Detection**: Randomized user agents, viewport sizes, and request delays
- **Error Resilience**: Retry mechanisms and graceful failure handling

**Site-Specific Implementations:**
 created specialized scrapers for:
- **Amazon Egypt**: Complex product grid with dynamic loading
- **Jumia**: Category-based navigation with price variations
- **Noon**: Multi-vendor marketplace with different layouts
- **ElBadr**: Local Egyptian retailer with unique structure

**Anti-Detection Techniques:**
- **User Agent Rotation**: Mimics real browser behavior
- **Request Timing**: Random delays between pages (1-3 seconds)
- **Browser Automation**: Puppeteer with stealth plugin removes automation signatures
- **Viewport Randomization**: Different screen sizes simulate various devices

### ğŸš€ Redis Caching Strategy

**Why Redis for High-Performance Caching:**
- **In-Memory Speed**: Sub-millisecond response times for cached data
- **Data Structures**: Rich data types support complex caching scenarios
- **Persistence Options**: Balances performance with data durability
- **Atomic Operations**: Pipeline commands reduce network round trips


**Intelligent Cache Management:**
- **TTL Strategy**: 10-minute default with 1-hour maximum prevents stale data
- **Pipeline Operations**: Batch Redis commands reduce latency by 60%
- **Cache Warming**: Pre-loads popular searches during off-peak hours
- **Selective Invalidation**: Updates specific cache entries rather than clearing all


### ğŸ—„ï¸ Database Design & Optimization

**MongoDB + Mongoose Implementation:**

**Schema Design Principles:**
- **Document Structure**: Optimized for read-heavy workloads typical in price comparison
- **Indexing Strategy**: Compound indexes on frequently queried fields (email + active, keyword + timestamp)
- **Validation Rules**: Schema-level validation prevents data corruption
- **Reference Management**: Balanced embedding vs referencing based on query patterns


### ğŸ”„ Advanced API Controller Logic

**Request Processing Architecture:**

**Error Handling Strategy:**
- **Global Error Middleware**: Centralized error processing and logging
- **Environment-Aware Responses**: Detailed errors in development, sanitized in production
- **Operational vs Programming Errors**: Different handling strategies for each error type
- **User-Friendly Messages**: Translate technical errors into actionable user guidance

**Response Optimization:**
- **Data Filtering**: Server-side filtering reduces bandwidth usage
- **Pagination**: Cursor-based pagination for large datasets
- **Compression**: Gzip compression reduces response size by 60%
- **Caching Headers**: HTTP cache control optimizes client-side caching

**Business Logic Features:**
- **Source Aggregation**: Combines results from multiple e-commerce sites
- **Price Comparison**: Real-time price analysis and sorting
- **Search Analytics**: Tracks user behavior for insights and recommendations
- **Performance Monitoring**: Built-in metrics collection for optimization

## ï¿½ğŸš€ Getting Started

### Prerequisites

- Node.js >= 14.x
- MongoDB >= 4.4
- Redis >= 6.0
- Docker & Docker Compose
- kubectl (for Kubernetes deployment)
- Terraform (for infrastructure provisioning)

### Local Development Setup

1. Clone the repository:

```bash
git clone 
cd PricePointScout
```

2. Install dependencies:

```bash
npm install
```

3. Set up environment variables:

```bash
cp example.config.env config.env
# Edit config.env with your configurations
```

4. Start development server:

```bash
npm run dev
```

### ğŸ³ Docker Development Environment

```bash
# Start all services with monitoring
docker-compose up -d

# View application logs
docker-compose logs -f app

# Scale application instances
docker-compose up -d --scale app=3

# Stop all services
docker-compose down
```

### â˜¸ï¸ Kubernetes Deployment

#### Local Development (Minikube)

```bash
# Start minikube
minikube start

# Deploy to local cluster
cd kubernetes-minikube
kubectl apply -f .

# Enable ingress
minikube addons enable ingress

# Get service URL
minikube service pricepointscout-service --url
```

#### Production (Azure AKS)

```bash
# Provision AKS cluster with Terraform
cd terraform-AKS-Azure
terraform init
terraform plan
terraform apply

# Configure kubectl
az aks get-credentials --resource-group <rg-name> --name <cluster-name>

# Deploy application
cd ../kubernetes-AKS
./deploy-complete.sh

# Check deployment status
kubectl get pods -n pps-namespace
```

## ğŸ—ï¸ Infrastructure Architecture

### Cloud Infrastructure (Azure)

```yaml
Resource Group:
  â”œâ”€â”€ AKS Cluster
  â”‚   â”œâ”€â”€ Node Pool (3x Standard_B2s_v2)
  â”‚   â”œâ”€â”€ System Assigned Identity
  â”‚   â””â”€â”€ Network Profile (kubenet)
  â”œâ”€â”€ Virtual Network
  â”œâ”€â”€ Load Balancer
  â””â”€â”€ Public IP
```

### Application Stack

```yaml
Kubernetes Namespace: pps-namespace
â”œâ”€â”€ Deployments:
â”‚   â”œâ”€â”€ PricePointScout (3 replicas)
â”‚   â”œâ”€â”€ MongoDB StatefulSet (2 replicas)
â”‚   â””â”€â”€ Redis Deployment (1 replica)
â”œâ”€â”€ Services:
â”‚   â”œâ”€â”€ ClusterIP (internal communication)
â”‚   â””â”€â”€ LoadBalancer (external access)
â”œâ”€â”€ ConfigMaps:
â”‚   â””â”€â”€ Application configuration
â”œâ”€â”€ Secrets:
â”‚   â””â”€â”€ Database credentials, JWT secrets
â””â”€â”€ Ingress:
    â””â”€â”€ NGINX controller with SSL termination
```

### Monitoring Stack

```yaml
Monitoring Namespace: monitoring
â”œâ”€â”€ Prometheus Server
â”œâ”€â”€ Grafana Dashboard
â”œâ”€â”€ Node Exporter DaemonSet
â””â”€â”€ Custom Metrics Collection
```

## ğŸ”§ Configuration

### Environment Variables

```env
# Application Configuration
NODE_ENV=production
PORT=8080
HOST=0.0.0.0

# Database Configuration
DATABASE=mongodb://mongodb-service:27017/PricePointScout
REDIS_HOST=redis-service
REDIS_PORT=6379

# Authentication & Security
JWT_SECRET=your-super-secure-jwt-secret-key
JWT_EXPIRES_IN=90d
JWT_COOKIE_EXPIRES_IN=90

# Cache Configuration
CACHE_DURATION=600
MAX_CACHE_LIFETIME=3600

# Scraping Configuration
MAX_PAGES_PER_SOURCE=5
CONCURRENT_SCRAPERS=3
BROWSER_TIMEOUT=30000

# Monitoring
PROMETHEUS_PORT=9090
METRICS_ENABLED=true
```

### Kubernetes Configuration

```yaml
# ConfigMap for application settings
apiVersion: v1
kind: ConfigMap
metadata:
  name: pps-configmap
  namespace: pps-namespace
data:
  NODE_ENV: "production"
  PORT: "8080"
  REDIS_HOST: "redis-service"
  CACHE_DURATION: "600"
```

## ğŸ“š API Documentation

### ğŸ” Authentication System Design

**My JWT-Based Authentication Strategy:**

**Registration & Login Flow:**
- **Secure Registration**: Email validation, password strength requirements, and duplicate prevention
- **Token Generation**: JWT tokens with 90-day expiration stored in HTTP-only cookies
- **Login Security**: Bcrypt password verification with protection against timing attacks
- **Session Management**: Automatic token refresh and secure logout functionality

**Password Recovery Implementation:**
- **Crypto-Based Tokens**: Secure random tokens with 10-minute expiration
- **Email Integration**: Automated password reset emails with secure links
- **Token Validation**: Single-use tokens that expire after successful reset

### ğŸ›ï¸ Product Scraping API Architecture

**Multi-Source Data Aggregation:**

**Guest Access Features:**
- **Public Search**: Basic product search across selected e-commerce platforms
- **Rate Limiting**: 100 requests per 15-minute window to prevent abuse
- **Response Caching**: 10-minute cache TTL for identical searches

**Authenticated User Benefits:**
- **Advanced Filtering**: Price ranges, brand filtering, and custom sorting options
- **Search History**: Persistent search tracking and analytics
- **Priority Processing**: Faster response times and extended cache lifetime
- **Export Options**: Data export capabilities for power users

**Real-Time Data Processing:**
- **Parallel Scraping**: Concurrent requests to multiple sources reduce response time
- **Error Resilience**: Graceful handling of site failures with partial results
- **Cache Intelligence**: Smart cache invalidation based on product freshness

### ğŸ‘¤ User Management Features

**Profile Management:**
- **Secure Updates**: Real-time profile updates with validation
- **Privacy Controls**: Granular privacy settings for search history
- **Data Export**: GDPR-compliant data export functionality

**Search Analytics:**
- **Personal Dashboard**: Search history visualization and insights
- **Trend Analysis**: Personal shopping patterns and recommendations
- **Performance Metrics**: Cache hit rates and response time tracking

### ğŸ” Advanced Search Capabilities

**Smart Search Features:**
- **Keyword Intelligence**: Fuzzy matching and synonym recognition
- **Category Detection**: Automatic product categorization
- **Price Tracking**: Historical price data and trend analysis

**Filter & Sort Options:**
- **Dynamic Filtering**: Real-time filter application without page refresh
- **Custom Sorting**: Multiple sort criteria (price, rating, popularity)
- **Saved Filters**: Persistent filter preferences for repeat searches



## ğŸ§ª Testing Strategy & Quality Assurance

### My Comprehensive Testing Approach


Quality assurance requires testing at every level to catch issues before production deployment.

**Test Suite Architecture:**

**Unit Testing Philosophy:**
- **Component Isolation**: Each module tested independently with mocked dependencies
- **Coverage Goals**: 90%+ code coverage for critical business logic
- **Fast Feedback**: Sub-second test execution for rapid development cycles

**Integration Testing Strategy:**
- **API Endpoint Validation**: Complete request/response cycle testing
- **Database Operations**: Real database interactions with test data
- **Cache Behavior**: Redis integration and cache invalidation testing

**Performance & Load Testing:**
- **Response Time Benchmarks**: API endpoints under realistic load conditions
- **Concurrent User Simulation**: Multi-user scenarios to identify bottlenecks
- **Memory Usage Profiling**: Detection of memory leaks and optimization opportunities

**Specialized Scraper Testing:**
- **Website Compatibility**: Automated validation of scraper reliability
- **Data Extraction Accuracy**: Verification of product information parsing
- **Anti-Detection Effectiveness**: Testing stealth capabilities against protection systems


## ğŸ™ Acknowledgments

**build with DevOps Team special Docker Team**



